{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BIG DATA AND CLOUD COMPUTING - PROJECT\n"
      ],
      "metadata": {
        "id": "dSiue5UNXaG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authentication"
      ],
      "metadata": {
        "id": "fJP7LRUhuB-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = 'proj8824'\n"
      ],
      "metadata": {
        "id": "b4giTTb7uGjo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "!gcloud config set project {PROJECT_ID}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-Np9boHwRjQ",
        "outputId": "b2fe0cd4-f935-4802-bdaa-a260ec34dabe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Big Query Dataset Creation"
      ],
      "metadata": {
        "id": "xh-AXllddjax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery as bq\n",
        "\n",
        "client = bq.Client(project=PROJECT_ID)\n"
      ],
      "metadata": {
        "id": "TAsxzZeBwdRs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tables Creation"
      ],
      "metadata": {
        "id": "Ug1vmsesc_1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DATASET_ID = \"openimages\"\n",
        "\n",
        "# Dataset creation\n",
        "dataset_ref = client.dataset(DATASET_ID)\n",
        "dataset = bq.Dataset(dataset_ref)\n",
        "dataset.location = \"US\"\n",
        "client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "# Schema for Classes table\n",
        "classes_schema = [\n",
        "    bq.SchemaField(\"Label\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bq.SchemaField(\"Description\", \"STRING\", mode=\"REQUIRED\"),\n",
        "]\n",
        "\n",
        "# Define schema for image_labels table\n",
        "image_labels_schema = [\n",
        "    bq.SchemaField(\"ImageId\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bq.SchemaField(\"Label\", \"STRING\", mode=\"REQUIRED\"),\n",
        "]\n",
        "\n",
        "# Schema for relations table\n",
        "relations_schema = [\n",
        "    bq.SchemaField(\"ImageId\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bq.SchemaField(\"Label1\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bq.SchemaField(\"Relation\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    bq.SchemaField(\"Label2\", \"STRING\", mode=\"REQUIRED\"),\n",
        "]\n",
        "\n",
        "# Table creation\n",
        "tables = {\n",
        "    'classes': classes_schema,\n",
        "    'image_labels': image_labels_schema,\n",
        "    'relations': relations_schema\n",
        "}\n",
        "\n",
        "for table_id, schema in tables.items():\n",
        "    table_ref = dataset_ref.table(table_id)\n",
        "    table = bq.Table(table_ref, schema=schema)\n",
        "    client.create_table(table, exists_ok=True)\n",
        "\n",
        "print(\"BigQuery dataset and tables created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tquzWxGwwdwb",
        "outputId": "a83b0c1b-8874-4b4f-8f32-4c296e6ed121"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BigQuery dataset and tables created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data Into BigQuery"
      ],
      "metadata": {
        "id": "-tE8QlOndD44"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "image_labels_df = pd.read_csv('image-labels.csv')\n",
        "classes_df = pd.read_csv('classes.csv')\n",
        "relations_df = pd.read_csv('relations.csv')"
      ],
      "metadata": {
        "id": "mucfURbTIDaV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data from DataFrame to BigQuery table\n",
        "def load_data_to_bigquery(df, table_id):\n",
        "    job_config = bq.LoadJobConfig(autodetect=True)  # Let BigQuery determine the schema automatically\n",
        "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n",
        "    job.result()  # Wait for the job to complete\n",
        "\n",
        "# Loading the 'classes' data\n",
        "classes_table_id = f\"{PROJECT_ID}.openimages.classes\"\n",
        "load_data_to_bigquery(classes_df, classes_table_id)\n",
        "\n",
        "# Loading the 'image_labels' data\n",
        "image_labels_table_id = f\"{PROJECT_ID}.openimages.image_labels\"\n",
        "load_data_to_bigquery(image_labels_df, image_labels_table_id)\n",
        "\n",
        "# Loading the 'relations' data\n",
        "relations_table_id = f\"{PROJECT_ID}.openimages.relations\"\n",
        "load_data_to_bigquery(relations_df, relations_table_id)\n",
        "\n",
        "print(\"Data has been uploaded to BigQuery.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCI9-NzHIL69",
        "outputId": "816d4a34-073e-4067-a1c6-9251af830a3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been uploaded to BigQuery.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validating the Data Loading"
      ],
      "metadata": {
        "id": "X0CM19HXRHFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing the row counts for each table\n",
        "for table_name, dataframe in [('classes', classes_df), ('image_labels', image_labels_df), ('relations', relations_df)]:\n",
        "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n",
        "    table = client.get_table(table_id)  # Make an API request.\n",
        "    print(f\"The table {table_id} contains {table.num_rows} rows.\")\n",
        "\n",
        "    expected_row_count = len(dataframe.index)\n",
        "    print(f\"The DataFrame for {table_name} contains {expected_row_count} rows.\")\n",
        "\n",
        "    if expected_row_count == table.num_rows:\n",
        "        print(f\"Row count matches for {table_id}!\")\n",
        "    else:\n",
        "        print(f\"Row count mismatch for {table_id}!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd4wyoiYNtDl",
        "outputId": "f37ecabc-e950-4579-ff59-b6c518de7924"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The table proj8824.openimages.classes contains 601 rows.\n",
            "The DataFrame for classes contains 601 rows.\n",
            "Row count matches for proj8824.openimages.classes!\n",
            "The table proj8824.openimages.image_labels contains 550809 rows.\n",
            "The DataFrame for image_labels contains 550809 rows.\n",
            "Row count matches for proj8824.openimages.image_labels!\n",
            "The table proj8824.openimages.relations contains 2768 rows.\n",
            "The DataFrame for relations contains 2768 rows.\n",
            "Row count matches for proj8824.openimages.relations!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the first few rows\n",
        "for table_name in ['classes', 'image_labels', 'relations']:\n",
        "    query = f\"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{table_name}` LIMIT 5\"\n",
        "    query_job = client.query(query)\n",
        "\n",
        "    print(f\"Showing sample data for {table_name}:\")\n",
        "    for row in query_job.result():\n",
        "        print(dict(row))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX3THwR1NzZ-",
        "outputId": "ea9307c2-45fb-46f8-97ee-55667ebd2759"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Showing sample data for classes:\n",
            "{'Label': '/m/011k07', 'Description': 'Tortoise'}\n",
            "{'Label': '/m/011q46kg', 'Description': 'Container'}\n",
            "{'Label': '/m/012074', 'Description': 'Magpie'}\n",
            "{'Label': '/m/0120dh', 'Description': 'Sea turtle'}\n",
            "{'Label': '/m/01226z', 'Description': 'Football'}\n",
            "\n",
            "\n",
            "Showing sample data for image_labels:\n",
            "{'ImageId': '01054f0eadfb2d5a', 'Label': '/m/0_k2'}\n",
            "{'ImageId': '0d3786516a4d335e', 'Label': '/m/0_k2'}\n",
            "{'ImageId': '14da3cbe7b9bd730', 'Label': '/m/0_k2'}\n",
            "{'ImageId': '1564ad0dd401481c', 'Label': '/m/0_k2'}\n",
            "{'ImageId': 'c07604d8bfb3b93c', 'Label': '/m/0_k2'}\n",
            "\n",
            "\n",
            "Showing sample data for relations:\n",
            "{'ImageId': '214a5095725a829d', 'Label1': '/m/01yrx', 'Relation': 'inside_of', 'Label2': '/m/0k4j'}\n",
            "{'ImageId': 'e946e9130ec264a6', 'Label1': '/m/01yrx', 'Relation': 'inside_of', 'Label2': '/m/0k4j'}\n",
            "{'ImageId': 'f89aed52e139832b', 'Label1': '/m/04yx4', 'Relation': 'inside_of', 'Label2': '/m/0k4j'}\n",
            "{'ImageId': '2d9c4a7383cbbf33', 'Label1': '/m/04yx4', 'Relation': 'inside_of', 'Label2': '/m/0k4j'}\n",
            "{'ImageId': 'e105ea256c511b97', 'Label1': '/m/04yx4', 'Relation': 'inside_of', 'Label2': '/m/0k4j'}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the schema\n",
        "for table_name in ['classes', 'image_labels', 'relations']:\n",
        "    table_id = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n",
        "    table = client.get_table(table_id)  # Make an API request.\n",
        "    print(f\"Schema for {table_id}:\")\n",
        "    for schema_field in table.schema:\n",
        "        print(f\"{schema_field.name} - {schema_field.field_type}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry02VAJ0Q9eq",
        "outputId": "56168b26-f46d-4d2f-d130-b6de363206c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Schema for proj8824.openimages.classes:\n",
            "Label - STRING\n",
            "Description - STRING\n",
            "Schema for proj8824.openimages.image_labels:\n",
            "ImageId - STRING\n",
            "Label - STRING\n",
            "Schema for proj8824.openimages.relations:\n",
            "ImageId - STRING\n",
            "Label1 - STRING\n",
            "Relation - STRING\n",
            "Label2 - STRING\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating CSV for Vertex AI"
      ],
      "metadata": {
        "id": "BhYtiJY_daVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "PROJECT_ID = 'proj8824'\n",
        "BQ_CLIENT = bigquery.Client(project=PROJECT_ID)\n",
        "STORAGE_CLIENT = storage.Client(project=PROJECT_ID)\n",
        "\n",
        "\n",
        "SOURCE_BUCKET_NAME = 'bdcc_open_images_dataset'\n",
        "TARGET_BUCKET_NAME = 'proj8824.appspot.com'\n",
        "\n",
        "\n",
        "DATASET_ID = 'openimages'\n",
        "IMAGES_TABLE_NAME = 'image_labels'\n",
        "LABELS_TABLE_NAME = 'classes'\n",
        "\n",
        "# Specifying labels to include\n",
        "INCLUDE_LABEL_DESCRIPTIONS = [\n",
        "    'Chair', 'Desk', 'Bed', 'Bookcase', 'Door handle', 'Nightstand', 'Couch', 'Houseplant', 'Picture frame', 'Lamp'\n",
        "]\n",
        "\n",
        "# Query to fetch images, considering additional non-specified labels are acceptable\n",
        "query = f\"\"\"\n",
        "SELECT IL.ImageId, CL.Description\n",
        "FROM `{PROJECT_ID}.{DATASET_ID}.{IMAGES_TABLE_NAME}` AS IL\n",
        "JOIN `{PROJECT_ID}.{DATASET_ID}.{LABELS_TABLE_NAME}` AS CL ON IL.Label = CL.Label\n",
        "WHERE CL.Description IN UNNEST(@include_labels)\n",
        "GROUP BY IL.ImageId, CL.Description\n",
        "\"\"\"\n",
        "\n",
        "job_config = bigquery.QueryJobConfig(\n",
        "    query_parameters=[\n",
        "        bigquery.ArrayQueryParameter(\"include_labels\", \"STRING\", INCLUDE_LABEL_DESCRIPTIONS)\n",
        "    ]\n",
        ")\n",
        "\n",
        "query_job = BQ_CLIENT.query(query, job_config=job_config)\n",
        "results = query_job.result()\n",
        "\n",
        "# Organizing images by their label, ensuring uniqueness across categories\n",
        "used_images = set()\n",
        "images_by_label = {label: [] for label in INCLUDE_LABEL_DESCRIPTIONS}\n",
        "\n",
        "for row in results:\n",
        "    image_id = row[\"ImageId\"]\n",
        "    label = row[\"Description\"]\n",
        "    if image_id not in used_images and len(images_by_label[label]) < 100:\n",
        "        images_by_label[label].append(image_id)\n",
        "        used_images.add(image_id)  # Mark this image as used\n",
        "\n",
        "# Copying an image from the source to the target bucket and returning the target URI\n",
        "def copy_image_to_target_bucket(source_image_id):\n",
        "    source_blob_path = f\"images/{source_image_id}.jpg\"\n",
        "    target_blob_path = f\"ImageFiles/{source_image_id}.jpg\"\n",
        "    source_blob = STORAGE_CLIENT.bucket(SOURCE_BUCKET_NAME).blob(source_blob_path)\n",
        "    target_blob = STORAGE_CLIENT.bucket(TARGET_BUCKET_NAME).copy_blob(source_blob, STORAGE_CLIENT.bucket(TARGET_BUCKET_NAME), target_blob_path)\n",
        "    return f\"gs://{TARGET_BUCKET_NAME}/{target_blob_path}\"\n",
        "\n",
        "# Prepareing the CSV data\n",
        "csv_data = []\n",
        "\n",
        "for label, images in images_by_label.items():\n",
        "    for idx, image_id in enumerate(images):\n",
        "        # Determining the dataset split (training, validation, test) based on the index\n",
        "        if idx < 80:\n",
        "            data_type = 'training'\n",
        "        elif idx < 90:\n",
        "            data_type = 'validation'\n",
        "        else:\n",
        "            data_type = 'test'\n",
        "\n",
        "        # Copying the image to our bucket and getting the target URI\n",
        "        target_image_uri = copy_image_to_target_bucket(image_id)\n",
        "\n",
        "        # Appending the data to the CSV list\n",
        "        csv_data.append({\n",
        "            \"set\": data_type,\n",
        "            \"image_uri\": target_image_uri,\n",
        "            \"label\": label\n",
        "        })\n",
        "\n",
        "# Creating a dataframe\n",
        "df = pd.DataFrame(csv_data)\n",
        "\n",
        "# Saving the DataFrame to a CSV file\n",
        "csv_file_path = \"vertex_ai_dataset.csv\"\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"CSV file created at {csv_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htl3LHlYLQ71",
        "outputId": "25df6848-1d3d-4b0f-b40b-8a471fab87f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file created at vertex_ai_dataset.csv\n"
          ]
        }
      ]
    }
  ]
}